@book{Aggarwal2023-zk,
  title     = {Neural networks and deep learning: A textbook},
  author    = {Aggarwal, Charu C},
  publisher = {Springer Nature},
  month     = jun,
  year      = 2023,
  address   = {Cham, Switzerland},
  language  = {en}
}

@book{Aggarwal2022-xj,
  title     = {Machine learning for text},
  author    = {Aggarwal, Charu C},
  publisher = {Springer Nature},
  month     = may,
  year      = 2022,
  address   = {Cham, Switzerland},
  language  = {en}
}

@misc{ciampiconi2023survey,
  title         = {A survey and taxonomy of loss functions in machine learning},
  author        = {Lorenzo Ciampiconi and Adam Elwood and Marco Leonardi and Ashraf Mohamed and Alessandro Rozza},
  year          = 2023,
  eprint        = {2301.05579},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@misc{webpage,
  title        = {An Introduction to Machine Learning},
  howpublished = {\url{https://monkeylearn.com/machine-learning/}},
  note         = {Ngày truy cập: 2023-12-13}
}

  
@misc{webpage1,
  title        = {Regression vs. Classification in Machine Learning for Beginners},
  author       = {{John Terra}},
  year         = 2023,
  howpublished = {\url{https://www.simplilearn.com/regression-vs-classification-in-machine-learning-article}},
  note         = {Ngày truy cập: 2023-12-13}
}

  
@misc{webpage2,
  title        = {Workflow of a Machine Learning project},
  author       = {{Ayush Pant}},
  year         = 2019,
  howpublished = {\url{https://towardsdatascience.com/workflow-of-a-machine-learning-project-ec1dba419b94}},
  note         = {Ngày truy cập: 2023-12-13}
}

  
@misc{webpage3,
  title        = {Derivative of the Softmax Function and the Categorical Cross-Entropy Loss},
  author       = {{Thomas Kurbiel}},
  year         = 2021,
  howpublished = {\url{https://towardsdatascience.com/derivative-of-the-softmax-function-and-the-categorical-cross-entropy-loss-ffceefc081d1}},
  note         = {Ngày truy cập: 2023-12-13}
}


  
@misc{webpage5,
  title        = {A Brief Overview of Recurrent Neural Networks (RNN)},
  author       = {{Debasish Kalita}},
  year         = 2023,
  howpublished = {\url{https://www.analyticsvidhya.com/blog/2022/03/a-brief-overview-of-recurrent-neural-networks-rnn/}},
  note         = {Ngày truy cập: 2023-12-13}
}

  
@misc{webpage6,
  title        = {Recurrent Neural Networks cheatsheet},
  author       = {{Afshine Amidi}, {Shervine Amidi}},
  year         = 2019,
  howpublished = {\url{https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks}},
  note         = {Ngày truy cập: 2023-12-13}
}

  
@misc{webpage7,
  title        = {Why Long Short term Memory(LSTM) is called as a Long and Short both type of Memory?},
  author       = {{Cornelius}},
  year         = 2021,
  howpublished = {\url{https://stackoverflow.com/a/66766043/16187830}},
  note         = {Ngày truy cập: 2023-12-13}
}

  
@misc{webpage8,
  title        = {Word2Vec Research Paper Explained},
  author       = {{Nikhil Birajdar}},
  year         = 2021,
  howpublished = {\url{https://towardsdatascience.com/word2vec-research-paper-explained-205cb7eecc30}},
  note         = {Ngày truy cập: 2023-12-13}
}

  
@misc{webpage9,
  title        = {Word Embedding: Text Analysis: NLP: Part-3: GloVe},
  author       = {{Jaimin Mungalpara}},
  year         = 2021,
  howpublished = {\url{https://medium.com/nerd-for-tech/word-embedding-text-analysis-nlp-part-3-glove-and-fasttext-da21d074237a}},
  note         = {Ngày truy cập: 2023-12-13}
}

  
@misc{webpage10,
  title        = {Deep Learning là gì? Tổng quan về Deep Learning từ A-Z},
  author       = {{Hưng Nguyễn}},
  howpublished = {\url{https://vietnix.vn/deep-learning-la-gi/}},
  note         = {Ngày truy cập: 2023-12-13}
}

  
@misc{webpage11,
  title        = {Kernel (image processing)},
  year         = 2023,
  howpublished = {\url{https://en.wikipedia.org/wiki/Kernel_(image_processing)}},
  note         = {Ngày truy cập: 2023-12-13}
}

  
@misc{webpage12,
  title        = {Viblo - Word Embedding - Tìm hiểu khái niệm cơ bản trong NLP},
  author       = {{Bui Quang Manh}},
  year         = 2020,
  howpublished = {\url{https://viblo.asia/p/word-embedding-tim-hieu-khai-niem-co-ban-trong-nlp-1Je5E93G5nL}},
  note         = {Ngày truy cập: 2023-12-13}
}


@misc{webpage13,
  title        = {Word embedding là gì? Tại sao nó quan trọng?},
  year         = 2019,
  howpublished = {\url{https://trituenhantao.io/kien-thuc/word-embedding-la-gi-tai-sao-no-quan-trong/}},
  note         = {Ngày truy cập: 2023-12-13}
}

@misc{webpage14,
  title        = {Introduction to FastText Embeddings and its Implication},
  author       = {{Krithika V}, {Analytics Vidhya}},
  year         = 2023,
  howpublished = {\url{https://www.analyticsvidhya.com/blog/2023/01/introduction-to-fasttext-embeddings-and-its-implication/}},
  note         = {Ngày truy cập: 2023-12-13}
}

@misc{webpage15,
  title        = {200Lab - Google Colab là gì? Hướng dẫn sử dụng Google Colab},
  author       = {{Pum}},
  year         = 2022,
  howpublished = {\url{https://200lab.io/blog/google-colab-la-gi/}},
  note         = {Ngày truy cập: 2023-12-21}
}

@misc{webpage16,
  title        = {Bizfly Cloud - TensorFlow là gì? Vai trò của TensorFlow trong sự phát triển của học máy},
  author       = {{Linh Tô}},
  year         = 2021,
  howpublished = {\url{https://bizflycloud.vn/tin-tuc/tensorflow-la-gi-vai-tro-cua-tensorflow-trong-su-phat-trien-cua-hoc-may-20211104172943825.htm}},
  note         = {Ngày truy cập: 2023-12-21}
}

@misc{webpage17,
  title        = {GeeksforGeeks - Generating Word Cloud in Python},
  year         = 2021,
  howpublished = {\url{https://www.geeksforgeeks.org/generating-word-cloud-python/ }},
  note         = {Ngày truy cập: 2023-12-21}
}

@misc{webpage18,
  title        = {TEK4.VN - Sử dụng Pickle để ghi file nhị phân},
  howpublished = {\url{https://tek4.vn/khoa-hoc/lap-trinh-python-can-ban/su-dung-pickle-de-ghi-file-nhi-phan}},
  note         = {Ngày truy cập: 2023-12-21}
}

@misc{data,
  title        = {Toxic Comment Classification Challenge},
  year         = 2018,
  howpublished = {\url{https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/data}},
  note         = {Ngày truy cập: 2023-12-21}
}