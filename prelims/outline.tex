\newgeometry{left=2cm, top=1cm, right=2cm, bottom=1cm}

\noindent\begin{minipage}[t]{0.43\textwidth}
    \centering
    \fontsize{11pt}{16.5pt}
    \textbf{Trường ĐH Sư Phạm Kỹ Thuật TP.HCM}\\
    \textbf{Khoa CNTT}\\
    % \rule[12pt]{0.5\textwidth}{.4pt}
    *******
\end{minipage}

\begin{center}
    \fontsize{18pt}{27pt}
    \textbf{ĐỀ CƯƠNG LUẬN VĂN TỐT NGHIỆP}
\end{center}

\begin{table}[!h]
    \centering
    \begin{tabularx}{0.8\textwidth}{ X c }
        Họ và Tên SV thực hiện 1: Huỳnh Minh Phước   & Mã Số SV: 20133082 \\
        Họ và Tên SV thực hiện 2: Văn Mai Thanh Nhật & Mã Số SV: 20133076 \\
        Họ và Tên SV thực hiện 3: Trần Đông          & Mã Số SV: 20133035 \\
    \end{tabularx}
\end{table}

\begin{center}
    \begin{tabular}{p{0.35\textwidth} p{0.45\textwidth}}
        \multicolumn{2}{l}{Thời gian làm luận văn từ\hspace{3cm} đến} \\
        Chuyên ngành: & Kỹ thuật dữ liệu                              \\
        Tên luận văn: & Nhận diện văn bản tiêu cực sử dụng học máy    \\
        GV hướng dẫn: & TS. Trần Nhật Quang
    \end{tabular}
\end{center}

\textbf{Nhiệm Vụ Của Luận Văn :}
\begin{enumerate}
    \item Tìm hiểu các kiến trúc mạng neuron và các thuật toán dùng trong xử lý văn bản.
    \item Tìm hiểu về xử lí ngôn ngữ tự nhiên.
    \item Tìm hiểu các kỹ thuật nhúng từ (word embedding).
    \item Tìm hiểu các thư viện, module hỗ trợ học máy và học sâu như Tensorflow, Sklearn, \dots
    \item Tìm hiểu những kiến trúc học sâu như LSTM, RNN, Transformer, \dots và các mô hình tiền huấn luyện GPT, BERT, \dots
    \item Ứng dụng các kiến thức đã tìm hiểu vào việc xây dựng mô hình phát hiện từ ngữ độc hại.
    \item Áp dụng mô hình đã xây dựng vào những ứng dụng thực tiễn.
\end{enumerate}

\text{Đề cương viết luận văn:}

\begin{center}
    \textbf{MỤC LỤC}
\end{center}
\begin{enumerate}[label=\textbf{\arabic*.}]
    \item \textbf{Phần MỞ ĐẦU}
    \item \textbf{Phần NỘI DUNG: Gồm có 4 chương}
          \begin{enumerate}
              \item Chương 1: Tổng quan về học máy và học sâu
                    \begin{itemize}
                        \itemsep 0pt
                        \item Khái quát về học máy
                        \item Khái quát về học sâu
                    \end{itemize}
              \item Chương 2: Mạng neuron nhân tạo
                    \begin{itemize}
                        \item Mạng neuron nhân tạo
                        \item Mạng neuron tích chập - CNN (Convolutional Neural Network)
                        \item Mạng neuron hồi quy - RNN (Recurrent Neural Network)
                        \item Bộ nhớ dài-ngắn hạn - LSTM (Long Short-Term Memory)
                        \item Bộ nhớ tái phát - GRU (Gated Recurent Unit)
                    \end{itemize}
              \item Chương 3: Xử lý ngôn ngữ tự nhiên
                    \begin{itemize}
                        \item Xử lý ngôn ngữ tự nhiên
                        \item Kỹ thuật nhúng từ (Word embedding)
                        \item Ngữ cảnh (Contextual) và vai trò trong NLP
                        \item Mô hình Transformer
                        \item Tiếp cận nông và học sâu trong ứng dụng pre-training NLP
                        \item Mô hình BERT (Bidirectional Encoder Representations from Transformers)
                    \end{itemize}
              \item Chương 4: Xây dựng mô hình phát hiện từ ngữ độc hại
                    \begin{itemize}
                        \item Môi trường cài đặt và các thư viện sử dụng
                        \item Mô tả tập dữ liệu
                        \item Tiền xử lý dữ liệu
                        \item Thiết lập mô hình
                        \item Huấn luyện mô hình và đánh giá kết quả
                    \end{itemize}
              \item Chương 5: Ứng dụng mô hình vào thực tiễn
                    \begin{itemize}
                        \item Giới thiệu
                        \item Mục đích
                        \item Quá trình phát triển
                        \item Cách hoạt động
                    \end{itemize}
          \end{enumerate}
    \item \textbf{Phần KẾT LUẬN}
    \item Tài liệu tham khảo
          \begin{sloppypar}
              \begin{enumerate}[label={[\arabic*]}]
                  \item W. Garbe, SymSpell, Jun. 2012. [Online]. Available: \url{https://github.com/wolfgarbe/SymSpell}.
                  \item A. Vaswani, N. Shazeer, N. Parmar, et al., ``Attention is all you need,'' 2017. [Online]. Available: \url{https://arxiv.org/pdf/1706.03762.pdf}.
                  \item J. Devlin, M.-W. Chang, K. Lee, and K. N. Toutanova, ``Bert: Pre-training of deep bidirectional transformers for language understanding,'' 2018. [Online]. Available: \url{https://arxiv.org/abs/1810.04805}.
                  \item R. Sharma and M. Patel, ``Toxic comment classification using neural networks and machine learning,'' IARJSET, vol. 5, no. 9, pp. 47-52, Sep. 2018. DOI: \url{10.17148/iarjset.2018.597}.
                  \item S. Afshine Amidi, Recurrent neural networks cheatsheet, \url{https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks}, Ngày truy cập: 2023-12-13, 2019.
                  \item Ayush Pant, Workflow of a machine learning project, \url{https://towardsdatascience.com/workflow-of-a-machine-learning-project-ec1dba419b94}, Ngày truy cập: 2023-12-13, 2019.
                  \item Samia Khalid, Bert explained: A complete guide with theory and tutorial, \url{https://medium.com/@samia.khalid/bert-explained-a-complete-guide-with-theory-and-tutorial-3ac9ebc8fa7c}, Ngày truy cập: 2024-06-18, 2019.
                  \item Word embedding là gì? tại sao nó quan trọng? \url{https://trituenhantao.io/kien-thuc/word-embedding-la-gi-tai-sao-no-quan-trong/}, Ngày truy cập: 2023-12-13, 2019.
                  \item Bui Quang Manh, Viblo - word embedding - tìm hiểu khái niệm cơ bản trong nlp, \url{https://viblo.asia/p/word-embedding-tim-hieu-khai-niem-co-ban-trong-nlp-1Je5E93G5nL}, Ngày truy cập: 2023-12-13, 2020.
                  \item K. Dubey, R. Nair, M. U. Khan, and P. S. Shaikh, ``Toxic comment detection using lstm,'' in 2020 Third International Conference on Advances in Electronics, Computers and Communications (ICAECC), 2020, pp. 1-8. DOI: \url{10.1109/ICAECC50550.2020.9339521}.
                  \item V. Krešňáková, M. Sarnovsky, P. Butka, and K. Machova, ``Comparison of deep learning models and various text pre-processing techniques for the toxic comments classification,'' Applied Sciences, vol. 10, p. 8631, Dec. 2020. DOI: \url{10.3390/app10238631}.
                  \item Nguyet Viet Anh, Transformers - ``người máy biến hình'' biến đổi thế giới nlp, \url{https://viblo.asia/p/transformers-nguoi-may-bien-hinh-bien-doi-the-gioi-nlp-924lJPOXKPM}, Ngày truy cập: 2024-06-18, 2020.
                  \item Pham Dinh Khanh, Bài 36 - bert model, \url{https://phamdinhkhanh.github.io/2020/05/23/BERTModel.html}, Ngày truy cập: 2024-06-18, 2020.
                  \item Pham Dinh Khanh, Bài 4 - attention is all you need, \url{https://phamdinhkhanh.github.io/2019/06/18/AttentionLayer.html}, Ngày truy cập: 2024-06-18, 2020.
                  \item Pham Huu Quang, Bert, roberta, phobert, bertweet: Ứng dụng state-of-the-art pre-trained model cho bài toán phân loại văn bản, \url{https://viblo.asia/p/bert-roberta-phobert-bertweet-ung-dung-state-of-the-art-pre-trained-model-cho-bai-toan-phan-loai-van-ban-4P856PEWZY3}, Ngày truy cập: 2024-06-18, 2020.
                  \item The illustrated transformer, \url{https://jalammar.github.io/illustrated-transformer/}, Ngày truy cập: 2024-06-18, 2020.
                  \item Việt nam `lọt' top 5 ứng xử kém văn minh trên internet, \url{https://vtcnews.vn/viet-nam-lot-top-5-ung-xu-kem-van-minh-tren-internet-ar529256.html}, Ngày truy cập: 2024-06-18, 2020.
                  \item Jaimin Mungalpara, Word embedding: Text analysis: Nlp: Part-3: Glove, \url{https://medium.com/nerd-for-tech/word-embedding-text-analysis-nlp-part-3-glove-and-fasttext-da21d074237a}, Ngày truy cập: 2023-12-13, 2021.
                  \item Linh Tô, Bizfly cloud - tensorflow là gì? vai trò của tensorflow trong sự phát triển của học máy, \url{https://bizflycloud.vn/tin-tuc/tensorflow-la-gi-vai-tro-cua-tensorflow-trong-su-phat-trien-cua-hoc-may-20211104172943825.htm}, Ngày truy cập: 2023-12-21, 2021.
                  \item Thomas Kurbiel, Derivative of the softmax function and the categorical cross-entropy loss, \url{https://towardsdatascience.com/derivative-of-the-softmax-function-and-the-categorical-cross-entropy-loss-ffceefc081d1}, Ngày truy cập: 2023-12-13, 2021.
                  \item C. C. Aggarwal, Machine learning for text, en. Cham, Switzerland: Springer Nature, May 2022.
                  \item Pum, 200lab - google colab là gì? hướng dẫn sử dụng google colab, \url{https://200lab.io/blog/google-colab-la-gi/}, Ngày truy cập: 2023-12-21, 2022.
                  \item C. C. Aggarwal, Neural networks and deep learning: A textbook, en. Cham, Switzerland: Springer Nature, Jun. 2023.
                  \item L. Ciampiconi, A. Elwood, M. Leonardi, A. Mohamed, and A. Rozza, A survey and taxonomy of loss functions in machine learning, 2023. arXiv: 2301.05579 [cs.LG].
                  \item John Terra, Regression vs. classification in machine learning for beginners, \url{https://www.simplilearn.com/regression-vs-classification-in-machine-learning-article}, Ngày truy cập: 2023-12-13, 2023.
                  \item Kernel (image processing), \url{https://en.wikipedia.org/wiki/Kernel_(image_processing)}, Ngày truy cập: 2023-12-13, 2023.
                  \item A. Krithika V, Introduction to fasttext embeddings and its implication, \url{https://www.analyticsvidhya.com/blog/2023/01/introduction-to-fasttext-embeddings-and-its-implication/}, Ngày truy cập: 2023-12-13, 2023.
                  \item Natural language processing, \url{https://en.wikipedia.org/wiki/Natural_language_processing}, Ngày truy cập: 2024-06-18, 2023.
                  \item Toxic comments identification and classification using deep neural networks, \url{https://www.academia.edu/41458366/Toxic_Comments_Identification_and_Classification_Using_Deep_Neural_Networks}, Ngày truy cập: 2024-06-18, 2023.
                  \item Top 8 applications of natural language processing (nlp), \url{https://eastgate-software.com/top-8-applications-of-natural-language-processing-nlp/}, Ngày truy cập: 2024-06-18, 2024.
                  \item An introduction to machine learning, \url{https://monkeylearn.com/machine-learning/}, Ngày truy cập: 2023-12-13.
                  \item Hưng Nguyễn, Deep learning là gì? tổng quan về deep learning từ a-z, \url{https://vietnix.vn/deep-learning-la-gi/}, Ngày truy cập: 2023-12-13.
              \end{enumerate}
          \end{sloppypar}
\end{enumerate}

% plan
\newpage
\textbf{KẾ HOẠCH THỰC HIỆN}
\input{prelims/plan}

\noindent\begin{minipage}[t]{0.42\textwidth}
    \centering
    \textbf{Ý kiến của giáo viên hướng dẫn}
    % \rule[12pt]{0.5\textwidth}{.4pt}
\end{minipage}\hfil
\begin{minipage}[t]{0.57\textwidth}
    \centering
    \textit{Tp. Hồ Chí Minh, ngày\qquad tháng\qquad năm 2024}

    \textbf{Người viết đề cương}
    % \rule[12pt]{0.5\textwidth}{.4pt}
\end{minipage}
\restoregeometry